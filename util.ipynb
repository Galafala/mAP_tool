{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_coord(coord_str):\n",
    "    # 分割字符串\n",
    "    points = coord_str.split(';')\n",
    "\n",
    "    # 將每個點進一步分割為 x 和 y\n",
    "    point_coords = [point.split(',') for point in points]\n",
    "\n",
    "    # 將每對 x 和 y 轉換為浮點數\n",
    "    float_coords = [(float(x), float(y)) for x, y in point_coords]\n",
    "\n",
    "    # 將坐標轉換為 x1, y1, x2, y2 的格式\n",
    "    x1, y1, x2, y2 = float_coords[0][0], float_coords[0][1], float_coords[2][0], float_coords[2][1]\n",
    "\n",
    "    return x1, y1, x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "data_path = \"/home/nas/Research_Group/Personal/Ben/ocean_waste_detection/xml2txt/參賽者驗證資料集下載(500)_0912.xml\"\n",
    "\n",
    "tree = ET.parse(data_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "results = {}\n",
    "childs = root.iter()\n",
    "name = ''\n",
    "for child in childs:\n",
    "    if child.tag not in ['image', 'polygon']:\n",
    "        continue\n",
    "\n",
    "    if child.tag == 'image':\n",
    "        name = child.attrib['name']\n",
    "        results[name] = {\"boxes\": [], \"labels\": []}\n",
    "\n",
    "    elif child.tag == 'polygon':\n",
    "        label = child.attrib['label']\n",
    "        points = child.attrib['points']\n",
    "        points = convert_to_coord(points) # (x1, y1, x2, y2)\n",
    "        results[name][\"boxes\"].append(points)\n",
    "        results[name][\"labels\"].append(label)\n",
    "\n",
    "\"\"\"\n",
    "I want to store the results to json file\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "with open('result.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(results, fp, ensure_ascii=False, indent=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I want read the json file\n",
    "\"\"\"\n",
    "import json\n",
    "json_path = '/Users/ben/Desktop/Programing/Python/evaluate/result.json'\n",
    "with open(json_path, 'r', encoding='utf-8') as fp:\n",
    "    results = json.load(fp)\n",
    "\n",
    "infos = results['result']\n",
    "\n",
    "results = {}\n",
    "for info in infos:\n",
    "    name = info['IMG_PATH'].split('/')[-1]\n",
    "    results[name] = {\"boxes\": [], \"labels\": [], \"scores\": []}\n",
    "    boxes = info['BOUNDING_BOX']\n",
    "\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box['x1'], box['y1'], box['x2'], box['y2']\n",
    "        results[name][\"boxes\"].append([x1, y1, x2, y2])\n",
    "        label = box['label_id']\n",
    "        results[name][\"labels\"].append(label)\n",
    "        score = box['score']\n",
    "        results[name][\"scores\"].append(score)\n",
    "\n",
    "with open('pred.json', 'w', encoding='utf-8') as fp:\n",
    "  json.dump(results, fp, ensure_ascii=False, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.107234\n",
      "mrec [ 0. nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan  1.] mpre [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "WASTE_18 nan Number of objects: 0\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/lpdf4tns5dj0rk1jwngwdlbc0000gn/T/ipykernel_82832/896829085.py:95: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = cumulative_true_positives / num_annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def calculate_intersection_area(rect1, rect2):\n",
    "    x_overlap = max(0, min(rect1[2], rect2[2]) - max(rect1[0], rect2[0]))\n",
    "    y_overlap = max(0, min(rect1[3], rect2[3]) - max(rect1[1], rect2[1]))\n",
    "\n",
    "    intersection_area = x_overlap * y_overlap\n",
    "    return intersection_area\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    # 計算兩個框的交集和聯集\n",
    "    intersection = calculate_intersection_area(box1, box2)\n",
    "    union = (box1[2] - box1[0]) * (box1[3] - box1[1]) + (box2[2] - box2[0]) * (box2[3] - box2[1]) - intersection\n",
    "\n",
    "    # 計算 IoU\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou\n",
    "\n",
    "def calculate_ap(precision, recall):\n",
    "    # 計算平均精確度 (AP)\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "    print(\"mrec\", mrec, \"mpre\", mpre)\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = max(mpre[i - 1], mpre[i])\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "def evaluate_mAP(predictions, targets):\n",
    "    all_boxes = {}\n",
    "    all_labels = {}\n",
    "    all_scores = {}\n",
    "\n",
    "    # 整理預測和真實框的資訊\n",
    "    for image_id, prediction_info in predictions.items():\n",
    "        boxes = np.array(prediction_info[\"boxes\"])\n",
    "        labels = prediction_info[\"labels\"]\n",
    "        scores = prediction_info[\"scores\"]\n",
    "\n",
    "        all_boxes[image_id] = boxes\n",
    "        all_labels[image_id] = labels\n",
    "        all_scores[image_id] = scores\n",
    "\n",
    "    # 計算 mAP\n",
    "    class_ids = [f\"WASTE_{i}\" for i in range(1, 21)]\n",
    "    average_precisions = []\n",
    "    for class_id in class_ids:  # 假設有 20 類別\n",
    "        class_id = \"WASTE_18\"\n",
    "        true_positives = []\n",
    "        scores = []\n",
    "        num_annotations = 0\n",
    "\n",
    "        for image_id, targets_info in targets.items():\n",
    "            if class_id in targets_info[\"labels\"]:\n",
    "                num_annotations += 1\n",
    "\n",
    "            if image_id not in all_boxes:\n",
    "                continue\n",
    "\n",
    "            # 選擇預測結果中指定類別的框\n",
    "            class_mask = np.array(all_labels[image_id]) == class_id\n",
    "            boxes = []\n",
    "            box_scores = []\n",
    "            for i, info in enumerate(class_mask):\n",
    "                if info:\n",
    "                    boxes.append(all_boxes[image_id][i])\n",
    "                    box_scores.append(all_scores[image_id][i])\n",
    "\n",
    "            if len(boxes) == 0:\n",
    "                true_positives.append(0)\n",
    "                scores.append(0)\n",
    "                continue\n",
    "\n",
    "            # 選擇真實框中指定類別的框\n",
    "            true_mask = np.array(targets_info[\"labels\"]) == class_id\n",
    "            true_boxes = np.array(targets_info[\"boxes\"])[true_mask]\n",
    "\n",
    "            # 計算 IoU\n",
    "            ious = np.array([calculate_iou(box, true_box) for box in boxes for true_box in true_boxes])\n",
    "\n",
    "            # 判斷每個預測框是否為正確檢測\n",
    "            true_positive = (ious >= 0.5).any()\n",
    "            true_positives.append(true_positive)\n",
    "            scores.append(np.max(box_scores))\n",
    "\n",
    "        print(sum(scores))\n",
    "        # 計算精確度和召回率\n",
    "        scores = np.array(scores)\n",
    "        true_positives = np.array(true_positives)\n",
    "        indices = np.argsort(-scores)\n",
    "        true_positives = true_positives[indices]\n",
    "        cumulative_true_positives = np.cumsum(true_positives)\n",
    "        recall = cumulative_true_positives / num_annotations\n",
    "        precision = cumulative_true_positives / np.arange(1, len(true_positives) + 1)\n",
    "        # 計算 AP 並添加到 average_precisions 中\n",
    "        ap = calculate_ap(precision, recall)\n",
    "        if ap:\n",
    "            average_precisions.append(ap)\n",
    "        else:\n",
    "            average_precisions.append(0)\n",
    "        print(class_id, ap, \"Number of objects:\", num_annotations)\n",
    "        break\n",
    "            \n",
    "\n",
    "    # 計算 mAP\n",
    "    mAP = np.mean(average_precisions)\n",
    "    return mAP\n",
    "\n",
    "# 使用範例\n",
    "pred_path = \"/Users/ben/Desktop/test.json\"\n",
    "target_path = \"/Users/ben/Desktop/result.json\"\n",
    "\n",
    "with open(pred_path, 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "with open(target_path, 'r') as f:\n",
    "    targets = json.load(f)\n",
    "\n",
    "mAP = evaluate_mAP(predictions, targets)\n",
    "\n",
    "print(mAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
